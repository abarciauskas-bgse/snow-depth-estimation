{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67e5060-38af-430f-a10d-f79ccb34656e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshapely\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeometry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m shape, Point\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from shapely.geometry import shape, Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dda4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = joblib.load('random_forest_model.pkl')\n",
    "\n",
    "# Load scalers\n",
    "X_scaler = joblib.load('X_scaler.pkl')\n",
    "Y_scaler = joblib.load('Y_scaler.pkl')\n",
    "with open('ski_areas.geojson', 'r') as f:\n",
    "    ski_areas = json.load(f)\n",
    "crystal_mountain_area = [site for site in ski_areas['features'] if site['properties']['name'] == 'Crystal Mountain'][0]\n",
    "crystal_polygon = shape(crystal_mountain_area['geometry'])\n",
    "crystal_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017997ac-603d-47e1-b4f6-0b909a7f1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://aimees-snow-project/results.parquet ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff37ed1c-932b-430d-93b9-0b48900f32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "results_df = pd.read_parquet('results.parquet')\n",
    "results_df = results_df.dropna(subset=['fsca'])\n",
    "results_df['datetime'] = pd.to_datetime(results_df['time'])\n",
    "results_df['day'] = results_df['datetime'].dt.day\n",
    "results_df['month'] = results_df['datetime'].dt.month\n",
    "results_df['year'] = results_df['datetime'].dt.year\n",
    "results_df.loc[~results_df['fsca'].between(0, 1000), 'fsca'] = None\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8954ea-3a9b-4188-86d2-e42bf05019f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [\"red\", \"green\", \"blue\", \"coastal\", \"nir08\", \"swir16\", \"swir22\", \"fsca\", \"latitude\", \"longitude\", \"month\"]\n",
    "x_input_data = results_df[input_columns]\n",
    "x_scaled = X_scaler.transform(x_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9b6bf-0a7d-4396-8ee8-5cf4fbce3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = model.predict(x_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c317f-6bb2-4057-8d7d-5c2c4390b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled = Y_scaler.inverse_transform([[pred] for pred in y_pred])\n",
    "results_df['snow_depth_prediction'] = y_scaled\n",
    "results_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2b931-c52d-481d-b4a4-24eda4ac7862",
   "metadata": {},
   "source": [
    "### Only represent one pixel per day\n",
    "\n",
    "Reduce overlapping pixels: group by day, lat, lon and pick the highest value for that pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ab6a2-daa5-4789-94fc-c70c247bffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_by_day = results_df.groupby(['year', 'month', 'day', 'latitude', 'longitude']).agg({'snow_depth_prediction': 'max'}).reset_index(level=[3,4])\n",
    "max_by_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a621e-22b8-40ef-86ba-084c8223029b",
   "metadata": {},
   "source": [
    "### Check each day has pixels that cover the entire polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f75c1-97b9-4bb2-9370-33f5eb1d1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_daily_coverage(rows, target_polygon):\n",
    "    # Create points from your DataFrame\n",
    "    points = [Point(lon, lat) for lon, lat in zip(rows['longitude'], rows['latitude'])]\n",
    "\n",
    "    # Check if all points are within the polygon\n",
    "    points_in_polygon = [point.within(target_polygon) for point in points]\n",
    "    coverage_percentage = sum(points_in_polygon) / len(points_in_polygon) * 100\n",
    "    return coverage_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598a3a6-4be7-49c8-8180-3c1e0171aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for daily_index in max_by_day.index.unique():\n",
    "    rows = max_by_day.loc[daily_index]\n",
    "    coverage_percentage = check_daily_coverage(rows, crystal_polygon)\n",
    "    if coverage_percentage < 99:\n",
    "        print(f\"Day {daily_index} has {coverage_percentage}% coverage\")\n",
    "        # remove from group if <99% coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4426b4-8414-4c7e-a1bc-d6b886e507f3",
   "metadata": {},
   "source": [
    "### Calculate the snow volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da616ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we have a matrix of observations, identified by datetime and a snow depth prediction for each pixel.\n",
    "# We can multiply those by the size of each pixel to get the area of snow.\n",
    "# Then we can sum those up to get the total area of snow for each year.\n",
    "area_of_each_pixel = 30 * 30\n",
    "max_by_day['snow_volume_prediction'] = max_by_day['snow_depth_prediction'] * area_of_each_pixel\n",
    "max_by_day['snow_volume_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba2153-6cd3-4f0a-a6d8-f0cfbf0efa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53551215-e622-4445-b3b5-77794e4f8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called 'df'\n",
    "# Create a datetime column for better time handling\n",
    "max_by_day['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# Create animated scatter mapbox\n",
    "fig = px.scatter_mapbox(\n",
    "    max_by_day, \n",
    "    lat=\"latitude\", \n",
    "    lon=\"longitude\",\n",
    "    color=\"value\",\n",
    "    animation_frame=\"date\",  # This creates the time slider\n",
    "    hover_data=[\"snow_volume_prediction\"],\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    size_max=15,\n",
    "    zoom=3,\n",
    "    mapbox_style=\"open-street-map\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Time-series Map of snow_volume_prediction\",\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db3fc11-dc35-44d3-9e97-07d244e1945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in /home/ec2-user/.local/lib/python3.9/site-packages (6.3.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from plotly) (2.5.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/.local/lib/python3.9/site-packages (from plotly) (25.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8306cc-00fe-4a03-8568-da56ef603b72",
   "metadata": {},
   "source": [
    "### Calculate the monthly average across the daily max volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddfc00f-38e0-4731-a30f-0e640a25037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_month = max_by_day.groupby(['year', 'month']).agg({'snow_volume_prediction': 'mean'})\n",
    "avg_by_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb5b12-10a1-40cf-a678-d958fadc549c",
   "metadata": {},
   "source": [
    "### Calculate the sum for each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b2ccb-3001-409b-b5ea-091f4866cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snow_season(month, year):\n",
    "    \"\"\"Convert month/year to snow season year\"\"\"\n",
    "    if month >= 11:  # Nov, Dec\n",
    "        return f\"{int(year)}-{int(year)+1}\"  # Snow season starts this year\n",
    "    elif month <= 4:  # Jan, Feb, Mar, Apr\n",
    "        return f\"{int(year)-1}-{int(year)}\"  # Snow season started previous year\n",
    "    else:\n",
    "        return None  # Not in snow season (May-Oct)\n",
    "\n",
    "# Apply to your DataFrame\n",
    "avg_by_month = avg_by_month.reset_index()  # Convert index to columns temporarily\n",
    "avg_by_month['snow_season'] = avg_by_month.apply(lambda row: get_snow_season(row['month'], row['year']), axis=1)\n",
    "\n",
    "# Filter to only snow season months and group\n",
    "snow_season_data = avg_by_month[avg_by_month['snow_season'].notna()]\n",
    "grouped = snow_season_data.groupby('snow_season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae142a7e-dde3-4141-8925-58a2753470a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_incomplete_seasons = grouped.filter(lambda group: len(group) == 6, dropna=True)\n",
    "sum_by_season = filter_incomplete_seasons.groupby('snow_season').agg({'snow_volume_prediction': 'sum'})\n",
    "sum_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c28aa0-f7de-4281-9c02-c4318af7905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and set all indices as xticks\n",
    "ax = sum_by_season.plot(figsize=(12,6))\n",
    "ax.set_xticks(range(len(sum_by_season.index)))\n",
    "ax.set_xticklabels(sum_by_season.index)\n",
    "plt.xticks(rotation=45)  # Rotate if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab52ed-f813-46da-bf5c-ee7dc660a0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
