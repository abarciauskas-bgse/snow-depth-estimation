{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dda4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = joblib.load('random_forest_model.pkl')\n",
    "\n",
    "# Load scalers\n",
    "X_scaler = joblib.load('X_scaler.pkl')\n",
    "Y_scaler = joblib.load('Y_scaler.pkl')\n",
    "with open('ski_areas.geojson', 'r') as f:\n",
    "    ski_areas = json.load(f)\n",
    "crystal_mountain_area = [site for site in ski_areas['features'] if site['properties']['name'] == 'Crystal Mountain'][0]\n",
    "crystal_polygon = shape(crystal_mountain_area['geometry'])\n",
    "crystal_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da616ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "results_df = pd.read_parquet('results.parquet')\n",
    "results_df = results_df.dropna(subset=['fsca'])\n",
    "results_df['datetime'] = pd.to_datetime(results_df['time'])\n",
    "results_df['day'] = results_df['datetime'].dt.day\n",
    "results_df['month'] = results_df['datetime'].dt.month\n",
    "results_df['year'] = results_df['datetime'].dt.year\n",
    "results_df.loc[~results_df['fsca'].between(0, 1000), 'fsca'] = None\n",
    "results_df.head()\n",
    "\n",
    "input_columns = [\"red\", \"green\", \"blue\", \"coastal\", \"nir08\", \"swir16\", \"swir22\", \"fsca\", \"latitude\", \"longitude\", \"month\"]\n",
    "x_input_data = results_df[input_columns]\n",
    "x_scaled = X_scaler.transform(x_input_data)\n",
    "\n",
    "y_pred = model.predict(x_scaled)\n",
    "y_pred\n",
    "y_scaled = Y_scaler.inverse_transform([[pred] for pred in y_pred])\n",
    "y_scaled\n",
    "results_df['snow_depth_prediction'] = y_scaled\n",
    "results_df.shape\n",
    "# reduce overlapping pixels: group by day, lat, lon and pick the highest value for that pixel\n",
    "max_by_day = results_df.groupby(['year', 'month', 'day', 'latitude', 'longitude']).agg({'snow_depth_prediction': 'max'}).reset_index(level=[3,4])\n",
    "# make sure that there are pixels that cover the entire polygon for each day\n",
    "def check_daily_coverage(df, target_polygon):\n",
    "    # Create points from your DataFrame\n",
    "    points = [Point(lon, lat) for lon, lat in zip(df['longitude'], df['latitude'])]\n",
    "\n",
    "    # Check if all points are within the polygon\n",
    "    points_in_polygon = [point.within(target_polygon) for point in points]\n",
    "    coverage_percentage = sum(points_in_polygon) / len(points_in_polygon) * 100\n",
    "    return coverage_percentage\n",
    "\n",
    "for group in max_by_day:\n",
    "    coverage_percentage = check_daily_coverage(group, crystal_polygon)\n",
    "    if coverage_percentage < 100:\n",
    "        print(f\"Day {group.day} has {coverage_percentage}% coverage\")\n",
    "        # remove from group\n",
    "\n",
    "avg_by_month = max_by_day.groupby(['year', 'month']).agg({'snow_depth_prediction': 'mean'})\n",
    "\n",
    "# what we have a matrix of observations, identified by datetime and a snow depth prediction for each pixel.\n",
    "# We can multiply those by the size of each pixel to get the area of snow.\n",
    "# Then we can sum those up to get the total area of snow for each year.\n",
    "area_of_each_pixel = 30 * 30\n",
    "avg_by_month['snow_volume_prediction'] = avg_by_month['snow_depth_prediction'] * area_of_each_pixel\n",
    "avg_by_month['snow_volume_prediction']\n",
    "# aggregate over the season (November through April)\n",
    "avg_by_month = avg_by_month[avg_by_month['month'].isin(range(11, 5))]\n",
    "sum_over_season = avg_by_month.groupby('year').agg({'snow_volume_prediction': 'sum'})\n",
    "sum_over_season.plot(kind='line', x='year', y='snow_volume_prediction')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
